#!/bin/bash

# OpenWebUI Container Test Script
# Direct container testing with fixed parameters for easy modification

set -e

# Function to show usage
show_usage() {
    echo "ğŸŒ OpenWebUI Container Test Script"
    echo "=================================="
    echo ""
    echo "Usage: $0 [COMMAND]"
    echo ""
    echo "Commands:"
    echo "  up      Start OpenWebUI container"
    echo "  down    Stop and remove container"
    echo "  logs    Show container logs"
    echo "  status  Show container status"
    echo "  test    Run OpenWebUI tests"
    echo "  help    Show this help message"
    echo ""
    echo "Examples:"
    echo "  $0 up       # Start container"
    echo "  $0 down     # Stop container"
    echo "  $0 logs     # View logs"
    echo "  $0 status   # Check status"
    echo "  $0 test     # Test OpenWebUI functionality"
    echo ""
    echo "Configuration (Fixed Parameters):"
    echo "  â€¢ Container Name: openwebui-test"
    echo "  â€¢ Port: 3000"
    echo "  â€¢ Data Path: ~/.openwebui:/app/backend/data"
    echo "  â€¢ Authentication: Disabled"
    echo "  â€¢ llama.cpp Endpoint: http://host.docker.internal:11434"
    echo "  â€¢ Model: devstral-2507:latest"
    echo "  â€¢ Context Window: 88832"
    echo "  â€¢ OpenAI API: Enabled"
    echo "  â€¢ Ollama API: Disabled"
    echo ""
    echo "Prerequisites:"
    echo "  â€¢ llama.cpp container must be running on port 11434"
    echo "  â€¢ Run './test-llama-cpp.sh up' first"
    echo ""
    echo "Web Interface:"
    echo "  â€¢ OpenWebUI: http://localhost:3000"
    echo "  â€¢ No login required (authentication disabled)"
    echo ""
    exit 0
}

# Function to check if llama.cpp is running
check_llama_cpp() {
    if ! curl -s http://localhost:11434/health >/dev/null 2>&1; then
        echo "âŒ llama.cpp container is not running or not responding"
        echo "ğŸ’¡ Please start llama.cpp first: './test-llama-cpp.sh up'"
        return 1
    fi
    
    if ! curl -s http://localhost:11434/v1/models | jq . >/dev/null 2>&1; then
        echo "âŒ llama.cpp models endpoint is not responding"
        echo "ğŸ’¡ Please check llama.cpp status: './test-llama-cpp.sh status'"
        return 1
    fi
    
    echo "âœ… llama.cpp container is running and responding"
    return 0
}

# Function to start OpenWebUI container
start_container() {
    echo "ğŸš€ Starting OpenWebUI Container"
    echo "==============================="
    
    CONTAINER_NAME="openwebui-test"
    
    # Check if llama.cpp is running
    if ! check_llama_cpp; then
        exit 1
    fi
    
    # Check if container is already running
    if docker ps -q --filter "name=$CONTAINER_NAME" | grep -q .; then
        echo "âš ï¸  Container is already running"
        show_status
        return 0
    fi
    
    # Remove existing container if it exists
    if docker ps -aq --filter "name=$CONTAINER_NAME" | grep -q .; then
        echo "ğŸ—‘ï¸  Removing existing container..."
        docker rm $CONTAINER_NAME
    fi

    # Clear persistent volume
    echo "ğŸ§¹ Clearing persistent volume..."
    if [ -d ~/.openwebui ]; then
        rm -rf ~/.openwebui/*
        echo "âœ… Cleared ~/.openwebui directory"
    else
        mkdir -p ~/.openwebui
        echo "âœ… Created ~/.openwebui directory"
    fi

    echo "ğŸ”„ Starting OpenWebUI container with fixed parameters..."
    echo "ğŸ“ Container Configuration:"
    echo "  â€¢ Authentication: Disabled"
    echo "  â€¢ OpenAI API: Enabled"
    echo "  â€¢ Ollama API: Disabled"
    echo "  â€¢ llama.cpp Endpoint: http://host.docker.internal:11434"
    echo "  â€¢ Model: devstral-2507:latest"
    echo "  â€¢ Context Window: 88832"
    echo "  â€¢ Data Volume: ~/.openwebui:/app/backend/data"
    echo ""
    
    # Start container with fixed parameters
    CONTAINER_ID=$(docker run -d \
        --name openwebui-test \
        -p 8080:8080 \
        -v ~/.openwebui:/app/backend/data \
        --add-host=host.docker.internal:host-gateway \
        -e WEBUI_AUTH=false \
        -e ENABLE_OLLAMA_API=false \
        -e ENABLE_OPENAI_API=true \
        -e OPENAI_API_BASE_URL=http://host.docker.internal:11434/v1 \
        -e OPENAI_API_KEY=sk-no-key-required \
        ghcr.io/open-webui/open-webui:latest)
    
    echo "âœ… Container started with ID: $CONTAINER_ID"
    echo "â³ Waiting 15 seconds for container to initialize..."
    sleep 15
    
    # Check if container is still running after startup
    if ! docker ps -q --filter "name=$CONTAINER_NAME" | grep -q .; then
        echo "âŒ Container stopped during startup"
        echo "ğŸ” Container logs:"
        docker logs $CONTAINER_NAME
        echo ""
        echo "ğŸ” Container status:"
        docker ps -a --filter "name=$CONTAINER_NAME"
        echo ""
        echo "âŒ Container startup failed"
        exit 1
    fi
    
    # Wait for OpenWebUI to be ready
    echo "â³ Waiting for OpenWebUI to be ready..."
    for i in {1..60}; do
        if curl -s http://localhost:3000 >/dev/null 2>&1; then
            echo "âœ… OpenWebUI is ready!"
            break
        fi
        
        # Check if container is still running
        if ! docker ps -q --filter "name=$CONTAINER_NAME" | grep -q .; then
            echo "âŒ Container stopped unexpectedly"
            echo "ğŸ” Container logs:"
            docker logs --tail 30 $CONTAINER_NAME
            echo ""
            echo "ğŸ” Container status:"
            docker ps -a --filter "name=$CONTAINER_NAME"
            exit 1
        fi
        
        if [ $i -eq 60 ]; then
            echo "âŒ OpenWebUI failed to start within 60 seconds"
            echo "ğŸ” Container logs:"
            docker logs --tail 30 $CONTAINER_NAME
            echo ""
            echo "ğŸ” Container status:"
            docker ps -a --filter "name=$CONTAINER_NAME"
            exit 1
        fi
        
        echo "â³ Attempt $i/60 - waiting for OpenWebUI..."
        sleep 1
    done
    
    # Test basic connectivity
    echo "ğŸ” Testing OpenWebUI connectivity..."
    
    # Test main page
    if curl -s http://localhost:3000 >/dev/null 2>&1; then
        echo "âœ… OpenWebUI main page accessible"
    else
        echo "âŒ OpenWebUI main page failed"
        exit 1
    fi
    
    echo ""
    echo "ğŸ‰ OpenWebUI container is running successfully!"
    echo "  â€¢ Container: openwebui-test"
    echo "  â€¢ Web Interface: http://localhost:3000"
    echo "  â€¢ Authentication: Disabled (no login required)"
    echo "  â€¢ Connected to llama.cpp: http://host.docker.internal:11434"
    echo "  â€¢ Available Model: devstral-2507:latest"
    echo "  â€¢ Context Window: 88832 tokens"
    echo ""
    echo "ğŸ§ª Run './test-openwebui.sh test' to test functionality"
    echo "ğŸŒ Open http://localhost:3000 in your browser"
}

# Function to stop container
stop_container() {
    echo "ğŸ›‘ Stopping OpenWebUI Container"
    echo "==============================="
    
    CONTAINER_NAME="openwebui-test"
    
    # Stop container
    if docker ps -q --filter "name=$CONTAINER_NAME" | grep -q .; then
        echo "ğŸ”„ Stopping container: $CONTAINER_NAME"
        docker stop $CONTAINER_NAME
    else
        echo "â„¹ï¸  Container is not running"
    fi

    # Remove container
    if docker ps -aq --filter "name=$CONTAINER_NAME" | grep -q .; then
        echo "ğŸ—‘ï¸  Removing container: $CONTAINER_NAME"
        docker rm $CONTAINER_NAME
    else
        echo "â„¹ï¸  Container does not exist"
    fi
    
    # Clear persistent volume
    echo "ğŸ§¹ Clearing persistent volume..."
    if [ -d ~/.openwebui ]; then
        rm -rf ~/.openwebui/*
        echo "âœ… Cleared ~/.openwebui directory"
    fi
    
    echo "âœ… Container stopped and removed!"
}

# Function to show container logs
show_logs() {
    CONTAINER_NAME="openwebui-test"
    
    echo "ğŸ“‹ OpenWebUI Container Logs"
    echo "=========================="
    
    if docker ps -q --filter "name=$CONTAINER_NAME" | grep -q .; then
        echo "ğŸ” Container Logs (Running):"
        echo "----------------------------"
        docker logs --tail 100 $CONTAINER_NAME
    elif docker ps -aq --filter "name=$CONTAINER_NAME" | grep -q .; then
        echo "ğŸ” Container Logs (Stopped):"
        echo "----------------------------"
        docker logs --tail 100 $CONTAINER_NAME
    else
        echo "âŒ Container does not exist"
        echo "ğŸ’¡ Run './test-openwebui.sh up' to start the container"
    fi
}

# Function to show container status
show_status() {
    CONTAINER_NAME="openwebui-test"
    
    echo "ğŸ“Š OpenWebUI Container Status"
    echo "============================="
    
    # Check llama.cpp status first
    echo "ğŸ” llama.cpp Dependency Status:"
    echo "-------------------------------"
    if check_llama_cpp; then
        echo "âœ… llama.cpp is ready"
    else
        echo "âŒ llama.cpp is not available"
        echo "ğŸ’¡ Start llama.cpp: './test-llama-cpp.sh up'"
        echo ""
    fi
    
    # Check container status
    if docker ps -q --filter "name=$CONTAINER_NAME" | grep -q .; then
        echo "âœ… Container is running"
        docker ps --filter "name=$CONTAINER_NAME" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
        echo ""
        
        # Test endpoints
        echo "ğŸ” OpenWebUI Status:"
        echo "-------------------"
        
        # Web interface check
        if curl -s http://localhost:3000 >/dev/null 2>&1; then
            echo "âœ… Web Interface: Available"
        else
            echo "âŒ Web Interface: Not responding"
        fi
        
        # Check if it can reach llama.cpp
        if curl -s http://localhost:11434/health >/dev/null 2>&1; then
            echo "âœ… llama.cpp Connection: Available"
        else
            echo "âŒ llama.cpp Connection: Not available"
        fi
        
    elif docker ps -aq --filter "name=$CONTAINER_NAME" | grep -q .; then
        echo "âŒ Container exists but is stopped"
        docker ps -a --filter "name=$CONTAINER_NAME" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
    else
        echo "âŒ Container does not exist"
    fi
    
    echo ""
    echo "ğŸŒ Access Information:"
    echo "  â€¢ Web Interface: http://localhost:3000"
    echo "  â€¢ Authentication: Disabled"
    echo "  â€¢ Default Model: devstral-2507:latest"
    echo "  â€¢ Context Window: 88832 tokens"
    echo "  â€¢ llama.cpp Endpoint: http://host.docker.internal:11434"
    echo ""
    echo "ğŸ“Š Quick Test Commands:"
    echo "  curl http://localhost:3000"
    echo "  open http://localhost:3000"
    echo "  ./test-openwebui.sh test"
}

# Function to run OpenWebUI tests
run_openwebui_tests() {
    echo "ğŸ§ª Running OpenWebUI Tests"
    echo "=========================="
    
    # Check if container is running
    if ! docker ps -q --filter "name=openwebui-test" | grep -q .; then
        echo "âŒ Container is not running"
        echo "ğŸ’¡ Run './test-openwebui.sh up' first"
        exit 1
    fi
    
    # Check if llama.cpp is running
    if ! check_llama_cpp; then
        echo "âŒ llama.cpp is not available"
        echo "ğŸ’¡ Run './test-llama-cpp.sh up' first"
        exit 1
    fi
    
    BASE_URL="http://localhost:3000"
    
    echo "ğŸ” Testing OpenWebUI functionality..."
    echo ""
    
    # Test 1: Web interface accessibility
    echo "ğŸ” Test 1: Web Interface Accessibility"
    echo "======================================"
    if curl -s "$BASE_URL" >/dev/null 2>&1; then
        echo "âœ… Web interface is accessible"
        
        # Check if it returns HTML content
        CONTENT=$(curl -s "$BASE_URL")
        if echo "$CONTENT" | grep -q "<html\|<HTML"; then
            echo "âœ… Returns valid HTML content"
        else
            echo "âŒ Does not return valid HTML content"
        fi
    else
        echo "âŒ Web interface is not accessible"
        return 1
    fi
    echo ""
    
    # Test 2: API endpoint availability
    echo "ğŸ” Test 2: API Endpoint Availability"
    echo "===================================="
    # Check if OpenWebUI API endpoints are available
    if curl -s "$BASE_URL/api/v1/auths" >/dev/null 2>&1; then
        echo "âœ… OpenWebUI API endpoints are available"
    else
        echo "âŒ OpenWebUI API endpoints are not available"
        echo "ğŸ” Checking alternative endpoints..."
        
        # Try other common endpoints
        if curl -s "$BASE_URL/api/config" >/dev/null 2>&1; then
            echo "âœ… Config API endpoint is available"
        elif curl -s "$BASE_URL/health" >/dev/null 2>&1; then
            echo "âœ… Health API endpoint is available"
        else
            echo "âŒ No API endpoints are responding"
        fi
    fi
    echo ""
    
    # Test 3: llama.cpp integration
    echo "ğŸ” Test 3: llama.cpp Integration"
    echo "================================"
    # Test if OpenWebUI can connect to llama.cpp
    if curl -s http://localhost:11434/health >/dev/null 2>&1; then
        echo "âœ… llama.cpp is reachable from host"
        
        # Check if models are available
        if curl -s http://localhost:11434/v1/models | jq . >/dev/null 2>&1; then
            echo "âœ… llama.cpp models endpoint is working"
            echo "ğŸ“‹ Available models:"
            curl -s http://localhost:11434/v1/models | jq -r '.data[].id'
        else
            echo "âŒ llama.cpp models endpoint is not working"
        fi
    else
        echo "âŒ llama.cpp is not reachable"
        return 1
    fi
    echo ""
    
    # Test 4: Configuration verification
    echo "ğŸ” Test 4: Configuration Verification"
    echo "====================================="
    echo "ğŸ“‹ Container Configuration:"
    echo "  â€¢ Authentication: Disabled"
    echo "  â€¢ OpenAI API: Enabled"
    echo "  â€¢ Ollama API: Disabled"
    echo "  â€¢ Default Model: devstral-2507:latest"
    echo "  â€¢ Context Window: 88832 tokens"
    echo "  â€¢ llama.cpp Endpoint: http://host.docker.internal:11434"
    echo "âœ… Configuration is set as expected"
    echo ""
    
    # Test 5: Volume persistence
    echo "ğŸ” Test 5: Volume Persistence"
    echo "============================="
    if [ -d ~/.openwebui ]; then
        echo "âœ… Data volume directory exists: ~/.openwebui"
        
        # Check if directory is writable
        if [ -w ~/.openwebui ]; then
            echo "âœ… Data volume is writable"
        else
            echo "âŒ Data volume is not writable"
        fi
        
        # Show directory contents
        echo "ğŸ“‹ Data directory contents:"
        ls -la ~/.openwebui/ 2>/dev/null || echo "  (empty or not accessible)"
    else
        echo "âŒ Data volume directory does not exist"
    fi
    echo ""
    
    # Test 6: Container resource usage
    echo "ğŸ” Test 6: Container Resource Usage"
    echo "==================================="
    CONTAINER_STATS=$(docker stats openwebui-test --no-stream --format "table {{.CPUPerc}}\t{{.MemUsage}}")
    if [ $? -eq 0 ]; then
        echo "âœ… Container resource usage:"
        echo "$CONTAINER_STATS"
    else
        echo "âŒ Could not get container resource usage"
    fi
    echo ""
    
    # Test 7: Network connectivity
    echo "ğŸ” Test 7: Network Connectivity"
    echo "==============================="
    # Test if container can reach external llama.cpp
    CONTAINER_NETWORK_TEST=$(docker exec openwebui-test curl -s http://host.docker.internal:11434/health 2>/dev/null)
    if [ $? -eq 0 ] && [ -n "$CONTAINER_NETWORK_TEST" ]; then
        echo "âœ… Container can reach llama.cpp: $CONTAINER_NETWORK_TEST"
    else
        echo "âŒ Container cannot reach llama.cpp"
        echo "ğŸ” Testing container network configuration..."
        docker exec openwebui-test ping -c 1 host.docker.internal >/dev/null 2>&1
        if [ $? -eq 0 ]; then
            echo "âœ… Container can ping host.docker.internal"
        else
            echo "âŒ Container cannot ping host.docker.internal"
        fi
    fi
    echo ""
    
    # Test 8: Log analysis
    echo "ğŸ” Test 8: Log Analysis"
    echo "======================="
    echo "ğŸ“‹ Recent container logs (last 10 lines):"
    docker logs --tail 10 openwebui-test 2>/dev/null || echo "âŒ Could not retrieve logs"
    echo ""
    
    echo "ğŸ¯ Test Summary"
    echo "==============="
    echo "âœ… Completed OpenWebUI functionality testing"
    echo "ğŸŒ Web interface tested for accessibility"
    echo "ğŸ”— llama.cpp integration verified"
    echo "ğŸ“‹ Configuration and persistence tested"
    echo "ğŸ”§ Container health and network connectivity verified"
    echo ""
    echo "ğŸš€ OpenWebUI is ready for use!"
    echo "ğŸŒ Access at: http://localhost:3000"
    echo "ğŸ¤– Model: devstral-2507:latest"
    echo "ğŸ“ Context: 88832 tokens"
    echo "ğŸ”“ No authentication required"
}

# Main script logic
case "${1:-}" in
    "up"|"start")
        start_container
        ;;
    "down"|"stop")
        stop_container
        ;;
    "logs")
        show_logs
        ;;
    "status")
        show_status
        ;;
    "test")
        run_openwebui_tests
        ;;
    "help"|"-h"|"--help")
        show_usage
        ;;
    "")
        show_usage
        ;;
    *)
        echo "âŒ Unknown command: $1"
        echo ""
        show_usage
        ;;
esac
